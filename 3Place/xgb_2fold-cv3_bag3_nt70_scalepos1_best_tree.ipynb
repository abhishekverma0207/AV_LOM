{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campaign  = pd.read_csv('input/campaign_data.csv')\n",
    "campaign1 = campaign.drop(['subject','email_url','email_body'],axis=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "def target_encode(trn_series=None,val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    #assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_val_series.index = val_series.index\n",
    "    \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), ft_val_series,ft_tst_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_clust = pd.read_csv('./input/user_cluster1.csv')\n",
    "all_data = all_data.merge(user_clust,on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['send_date'] = all_data.send_date.apply(lambda x: pd.datetime.strptime(x,'%d-%m-%Y %H:%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['send_dayofweek'] = all_data.send_date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'id', 'is_click', 'is_open', 'send_date', 'user_id',\n",
       "       'clust_id', 'send_dayofweek'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count features\n",
    "all_data['cnt_sd'] = all_data.groupby('send_date')['user_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.merge(campaign1,on='campaign_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'id', 'is_click', 'is_open', 'send_date', 'user_id',\n",
       "       'clust_id', 'send_dayofweek', 'cnt_sd', 'communication_type',\n",
       "       'total_links', 'no_of_internal_links', 'no_of_images',\n",
       "       'no_of_sections'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "all_data.loc[:,'communication_type'] = le1.fit_transform(all_data.communication_type)   \n",
    "all_data['usr_cnt'] = all_data.groupby('user_id')['user_id'].transform('count')\n",
    "all_data['cm_cnt'] = np.log(all_data.groupby('communication_type')['communication_type'].transform('count'))\n",
    "#all_data['camp_cnt'] = all_data.groupby('campaign_id')['campaign_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_data[len(train):]\n",
    "train = all_data[:len(train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del all_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {}\n",
    "xgb_params['eta'] = 0.07\n",
    "xgb_params['max_depth'] = 5\n",
    "xgb_params['max_leaves'] = 31\n",
    "xgb_params['max_bin'] = 10\n",
    "xgb_params['min_child_weight '] = 100\n",
    "xgb_params['subsample'] = 0.6\n",
    "xgb_params['colsample_bytree'] = 0.77\n",
    "xgb_params['objective'] = 'binary:logistic'\n",
    "xgb_params['eval_metric'] = 'auc'\n",
    "xgb_params['verbose'] = 1\n",
    "xgb_params['scale_pos_weight'] = 1.\n",
    "\n",
    "xgb_params['max_bin']=10\n",
    "xgb_params['max_delta_step']=1\n",
    "xgb_params['nthread']=7\n",
    "xgb_params['booster']='gbtree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "val_cid [29 30 31 32 33 34 35 36 37 38 39 40 41]\n",
      "(588141, 16) (435050, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.507239\ttrain-auc:0.630868\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 150 rounds.\n",
      "[10]\teval-auc:0.549008\ttrain-auc:0.941565\n",
      "[20]\teval-auc:0.54935\ttrain-auc:0.970986\n",
      "[30]\teval-auc:0.621005\ttrain-auc:0.985933\n",
      "[40]\teval-auc:0.623506\ttrain-auc:0.986568\n",
      "[50]\teval-auc:0.63699\ttrain-auc:0.987577\n",
      "[60]\teval-auc:0.643214\ttrain-auc:0.988096\n",
      "[69]\teval-auc:0.640067\ttrain-auc:0.98841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.513118\ttrain-auc:0.699374\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 150 rounds.\n",
      "[10]\teval-auc:0.549338\ttrain-auc:0.963648\n",
      "[20]\teval-auc:0.549279\ttrain-auc:0.972213\n",
      "[30]\teval-auc:0.585382\ttrain-auc:0.981735\n",
      "[40]\teval-auc:0.628757\ttrain-auc:0.986893\n",
      "[50]\teval-auc:0.648687\ttrain-auc:0.987708\n",
      "[60]\teval-auc:0.644673\ttrain-auc:0.988209\n",
      "[69]\teval-auc:0.643383\ttrain-auc:0.988605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.508098\ttrain-auc:0.654833\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 150 rounds.\n",
      "[10]\teval-auc:0.549292\ttrain-auc:0.96816\n",
      "[20]\teval-auc:0.549248\ttrain-auc:0.971653\n",
      "[30]\teval-auc:0.556878\ttrain-auc:0.977378\n",
      "[40]\teval-auc:0.630023\ttrain-auc:0.986505\n",
      "[50]\teval-auc:0.637828\ttrain-auc:0.986918\n",
      "[60]\teval-auc:0.647163\ttrain-auc:0.988098\n",
      "[69]\teval-auc:0.644905\ttrain-auc:0.98856\n",
      "Fold: 2\n",
      "val_cid [42 43 44 45 46 47 48 49 50 51 52 53 54]\n",
      "(435050, 16) (588141, 16)\n",
      "[0]\teval-auc:0.521143\ttrain-auc:0.660784\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 150 rounds.\n",
      "[10]\teval-auc:0.574698\ttrain-auc:0.959211\n",
      "[20]\teval-auc:0.582151\ttrain-auc:0.966154\n",
      "[30]\teval-auc:0.64668\ttrain-auc:0.981158\n",
      "[40]\teval-auc:0.646689\ttrain-auc:0.982213\n",
      "[50]\teval-auc:0.646649\ttrain-auc:0.982668\n",
      "[60]\teval-auc:0.669827\ttrain-auc:0.98389\n",
      "[69]\teval-auc:0.679231\ttrain-auc:0.984133\n",
      "[0]\teval-auc:0.513133\ttrain-auc:0.657905\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 150 rounds.\n",
      "[10]\teval-auc:0.574706\ttrain-auc:0.958659\n",
      "[20]\teval-auc:0.583715\ttrain-auc:0.96735\n",
      "[30]\teval-auc:0.650561\ttrain-auc:0.980521\n",
      "[40]\teval-auc:0.653512\ttrain-auc:0.982558\n",
      "[50]\teval-auc:0.661876\ttrain-auc:0.983443\n",
      "[60]\teval-auc:0.66456\ttrain-auc:0.983772\n",
      "[69]\teval-auc:0.663491\ttrain-auc:0.983995\n",
      "[0]\teval-auc:0.52116\ttrain-auc:0.693952\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 150 rounds.\n",
      "[10]\teval-auc:0.574725\ttrain-auc:0.960942\n",
      "[20]\teval-auc:0.602752\ttrain-auc:0.9715\n",
      "[30]\teval-auc:0.646011\ttrain-auc:0.980437\n",
      "[40]\teval-auc:0.650082\ttrain-auc:0.982535\n",
      "[50]\teval-auc:0.669828\ttrain-auc:0.983306\n",
      "[60]\teval-auc:0.673233\ttrain-auc:0.983707\n",
      "[69]\teval-auc:0.676993\ttrain-auc:0.984073\n"
     ]
    }
   ],
   "source": [
    "nfold =2\n",
    "kf = KFold(n_splits=nfold,random_state=123,shuffle=False)\n",
    "unq_campaign_id = np.sort(train.campaign_id.unique())\n",
    "\n",
    "test_subm = test[['id']]\n",
    "test_subm['is_click'] = 0\n",
    "train_score = train[['is_click']]\n",
    "train_score['pred'] = 0\n",
    "nbag = 3\n",
    "cf =0\n",
    "for train_index, test_index in kf.split(unq_campaign_id):\n",
    "    cf+=1\n",
    "    print('Fold:',cf)\n",
    "    \n",
    "    test1 = test.copy()\n",
    "    tr_cid = unq_campaign_id[train_index]\n",
    "    val_cid = unq_campaign_id[test_index]\n",
    "    print('val_cid',val_cid)\n",
    "\n",
    "    val = train[train.campaign_id.isin(tr_cid)]\n",
    "    train1 = train[train.campaign_id.isin(val_cid)]\n",
    "    print(val.shape,train1.shape)\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['user_id'],val['user_id'],\n",
    "                             test1['user_id'],train1.is_click,noise_level=.9,smoothing=5)\n",
    "    train1.loc[:,'mean_is_click'] = a1\n",
    "    val.loc[:,'mean_is_click'] = a2\n",
    "    test1.loc[:,'mean_is_click'] = a3\n",
    "\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['user_id'],val['user_id'],\n",
    "                             test1['user_id'],train1.is_open,noise_level=.9,smoothing=1.)\n",
    "    train1.loc[:,'mean_is_open'] = a1\n",
    "    val.loc[:,'mean_is_open'] = a2\n",
    "    test1.loc[:,'mean_is_open'] = a3\n",
    "\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['communication_type'],val['communication_type'],\n",
    "                             test1['communication_type'],train1.is_open,noise_level=0)\n",
    "    train1.loc[:,'mean_ct'] = a1\n",
    "    val.loc[:,'mean_ct'] = a2\n",
    "    test1.loc[:,'mean_ct'] = a3\n",
    "\n",
    "    #a1,a2,a3 = target_encode(train1['communication_type'],val['communication_type'],\n",
    "    #                         test1['communication_type'],train1.is_click,noise_level=0)\n",
    "    #train1.loc[:,'mean_clk_ct'] = a1\n",
    "    #val.loc[:,'mean_clk_ct'] = a2\n",
    "    #test1.loc[:,'mean_clk_ct'] = a3\n",
    "\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['clust_id'],val['clust_id'],\n",
    "                             test1['clust_id'],train1.is_click,noise_level=0)\n",
    "    train1.loc[:,'mean_clk_clust_id'] = a1\n",
    "    val.loc[:,'mean_clk_clust_id'] = a2\n",
    "    test1.loc[:,'mean_clk_clust_id'] = a3\n",
    "\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "    val.drop(['id','campaign_id','is_open','send_date',\n",
    "              'user_id','no_of_images','no_of_sections','no_of_internal_links'],axis=1,inplace=True)\n",
    "    train1.drop(['id','campaign_id','is_open','send_date',\n",
    "                 'user_id','no_of_images','no_of_sections','no_of_internal_links'],axis=1,inplace=True)\n",
    "    test1.drop(['id','campaign_id','is_open','send_date',\n",
    "               'user_id','no_of_images','no_of_sections','no_of_internal_links'],axis=1,inplace=True)\n",
    "    gc.collect()\n",
    "    train_y = train1.is_click.values\n",
    "    val_y = val.is_click.values\n",
    "    val.drop(['is_click'],axis=1,inplace=True)\n",
    "    train1.drop(['is_click'],axis=1,inplace=True)\n",
    "    test1.drop(['is_click'],axis=1,inplace=True)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(train1,label=train_y)\n",
    "    dval = xgb.DMatrix(val[train1.columns],label=val_y)\n",
    "    dtest =  xgb.DMatrix(test1[train1.columns])\n",
    "    gc.collect()\n",
    "    \n",
    "    evals_results = {}\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    for bg in range(nbag):\n",
    "        xgb_params['seed'] = 100*cf + bg\n",
    "        watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "        bst = xgb.train(xgb_params, dtrain, 70, watchlist,early_stopping_rounds=150,\n",
    "                        verbose_eval=10,maximize=True)\n",
    "    \n",
    "        train_score.loc[val.index,'pred'] += bst.predict(dval)\n",
    "        test_subm['is_click'] += bst.predict(dtest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_score['pred']/=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   is_click      pred\n",
       " 0       0.0  0.007969\n",
       " 1       0.0  0.010713\n",
       " 2       0.0  0.008167\n",
       " 3       0.0  0.008279\n",
       " 4       0.0  0.007871,          is_click      pred\n",
       " 1023186       0.0  0.008056\n",
       " 1023187       0.0  0.009954\n",
       " 1023188       1.0  0.007931\n",
       " 1023189       0.0  0.009988\n",
       " 1023190       0.0  0.007871)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score.head(5),train_score.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6603355706439776"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_score.is_click,train_score.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_subm['is_click'] /= nfold*nbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subm.to_csv('./xgb_2fold-cv2_bag3_nt70_scalepos1_nt70.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
