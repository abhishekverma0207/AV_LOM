{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campaign  = pd.read_csv('input/campaign_data.csv')\n",
    "'''\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "n_grams = vectorizer.fit_transform(campaign.subject)\n",
    "tsvd = TruncatedSVD(2,n_iter=250)\n",
    "tsvd_subject_feats = tsvd.fit_transform(n_grams)\n",
    "campaign['email_body'] = campaign.email_body.apply(lambda x: x.replace(\"\\r\\n\",\"\"))\n",
    "vectorizer = CountVectorizer(ngram_range=(1,4))\n",
    "n_grams = vectorizer.fit_transform(campaign.email_body)\n",
    "tsvd = TruncatedSVD(4,n_iter=250)\n",
    "tsvd_email_body_feats = tsvd.fit_transform(n_grams)\n",
    "for i in range(tsvd_subject_feats.shape[1]):\n",
    "    campaign.loc[:,'sub_'+str(i)] = tsvd_subject_feats[:,i]\n",
    "for i in range(tsvd_email_body_feats.shape[1]):\n",
    "    campaign.loc[:,'eb_'+str(i)] = tsvd_email_body_feats[:,i]\n",
    "'''\n",
    "campaign1 = campaign.drop(['subject','email_url','email_body'],axis=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "def target_encode(trn_series=None,val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    #assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_val_series.index = val_series.index\n",
    "    \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), ft_val_series,ft_tst_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_clust = pd.read_csv('./input/user_cluster1.csv')\n",
    "all_data = all_data.merge(user_clust,on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['send_date'] = all_data.send_date.apply(lambda x: pd.datetime.strptime(x,'%d-%m-%Y %H:%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['send_dayofweek'] = all_data.send_date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'id', 'is_click', 'is_open', 'send_date', 'user_id',\n",
       "       'clust_id', 'send_dayofweek'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count features\n",
    "all_data['cnt_sd'] = all_data.groupby('send_date')['user_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.merge(campaign1,on='campaign_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'id', 'is_click', 'is_open', 'send_date', 'user_id',\n",
       "       'clust_id', 'send_dayofweek', 'cnt_sd', 'communication_type',\n",
       "       'total_links', 'no_of_internal_links', 'no_of_images',\n",
       "       'no_of_sections'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "all_data.loc[:,'communication_type'] = le1.fit_transform(all_data.communication_type)   \n",
    "all_data['usr_cnt'] = all_data.groupby('user_id')['user_id'].transform('count')\n",
    "all_data['cm_cnt'] = np.log(all_data.groupby('communication_type')['communication_type'].transform('count'))\n",
    "#all_data['camp_cnt'] = all_data.groupby('campaign_id')['campaign_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_data[len(train):]\n",
    "train = all_data[:len(train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del all_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['num_leaves'] = 31\n",
    "lgb_params['max_depth'] = 5\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['min_data_in_leaf'] = 50\n",
    "lgb_params['subsample'] = 0.6\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['feature_fraction'] = 0.7,\n",
    "lgb_params['bagging_fraction'] = 0.77,\n",
    "lgb_params['objective'] = 'binary'\n",
    "lgb_params['metric'] = {'auc'}\n",
    "lgb_params['verbose'] = 1\n",
    "lgb_params['scale_pos_weight'] = 1.\n",
    "lgb_params['boosting_type'] = 'gbdt'\n",
    "lgb_params['min_split_gain'] = 0.0001\n",
    "#lgb_params['bagging_fraction'] = 0.7\n",
    "lgb_params['bagging_freq'] = 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "val_cid [29 30 31 32 33 34]\n",
      "(331628, 16) (691563, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.959499\tvalid's auc: 0.64165\n",
      "[20]\ttrain's auc: 0.960904\tvalid's auc: 0.682885\n",
      "[30]\ttrain's auc: 0.961472\tvalid's auc: 0.685754\n",
      "[40]\ttrain's auc: 0.961442\tvalid's auc: 0.685165\n",
      "[50]\ttrain's auc: 0.962194\tvalid's auc: 0.683764\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.96278\tvalid's auc: 0.686568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.959771\tvalid's auc: 0.681249\n",
      "[20]\ttrain's auc: 0.958168\tvalid's auc: 0.688639\n",
      "[30]\ttrain's auc: 0.958047\tvalid's auc: 0.688835\n",
      "[40]\ttrain's auc: 0.960492\tvalid's auc: 0.688832\n",
      "[50]\ttrain's auc: 0.961439\tvalid's auc: 0.688582\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[46]\ttrain's auc: 0.961925\tvalid's auc: 0.688432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.962265\tvalid's auc: 0.679662\n",
      "[20]\ttrain's auc: 0.963529\tvalid's auc: 0.682266\n",
      "[30]\ttrain's auc: 0.963445\tvalid's auc: 0.685344\n",
      "[40]\ttrain's auc: 0.963438\tvalid's auc: 0.690044\n",
      "[50]\ttrain's auc: 0.964154\tvalid's auc: 0.689997\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.964456\tvalid's auc: 0.687732\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.962724\tvalid's auc: 0.684908\n",
      "[20]\ttrain's auc: 0.961615\tvalid's auc: 0.685348\n",
      "[30]\ttrain's auc: 0.962596\tvalid's auc: 0.68143\n",
      "[40]\ttrain's auc: 0.962821\tvalid's auc: 0.682635\n",
      "[50]\ttrain's auc: 0.963031\tvalid's auc: 0.683734\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[51]\ttrain's auc: 0.963166\tvalid's auc: 0.683732\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.956924\tvalid's auc: 0.684525\n",
      "[20]\ttrain's auc: 0.958931\tvalid's auc: 0.687749\n",
      "[30]\ttrain's auc: 0.961068\tvalid's auc: 0.687752\n",
      "[40]\ttrain's auc: 0.96252\tvalid's auc: 0.687513\n",
      "[50]\ttrain's auc: 0.962575\tvalid's auc: 0.687599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[37]\ttrain's auc: 0.962846\tvalid's auc: 0.687325\n",
      "Fold: 2\n",
      "val_cid [35 36 37 38 39]\n",
      "(95814, 16) (927377, 16)\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957137\tvalid's auc: 0.744188\n",
      "[20]\ttrain's auc: 0.956535\tvalid's auc: 0.754693\n",
      "[30]\ttrain's auc: 0.957489\tvalid's auc: 0.758433\n",
      "[40]\ttrain's auc: 0.95723\tvalid's auc: 0.761839\n",
      "[50]\ttrain's auc: 0.957015\tvalid's auc: 0.761785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[34]\ttrain's auc: 0.957649\tvalid's auc: 0.757474\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.952665\tvalid's auc: 0.759722\n",
      "[20]\ttrain's auc: 0.955711\tvalid's auc: 0.755574\n",
      "[30]\ttrain's auc: 0.956282\tvalid's auc: 0.75638\n",
      "[40]\ttrain's auc: 0.956652\tvalid's auc: 0.76035\n",
      "[50]\ttrain's auc: 0.956908\tvalid's auc: 0.762324\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[54]\ttrain's auc: 0.957156\tvalid's auc: 0.761822\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.949622\tvalid's auc: 0.745809\n",
      "[20]\ttrain's auc: 0.954399\tvalid's auc: 0.755183\n",
      "[30]\ttrain's auc: 0.95521\tvalid's auc: 0.763086\n",
      "[40]\ttrain's auc: 0.955115\tvalid's auc: 0.763426\n",
      "[50]\ttrain's auc: 0.956063\tvalid's auc: 0.762984\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[54]\ttrain's auc: 0.956642\tvalid's auc: 0.762852\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.956036\tvalid's auc: 0.740168\n",
      "[20]\ttrain's auc: 0.956537\tvalid's auc: 0.759695\n",
      "[30]\ttrain's auc: 0.957196\tvalid's auc: 0.761407\n",
      "[40]\ttrain's auc: 0.957056\tvalid's auc: 0.75995\n",
      "[50]\ttrain's auc: 0.957319\tvalid's auc: 0.7601\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[54]\ttrain's auc: 0.957449\tvalid's auc: 0.76011\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957147\tvalid's auc: 0.740874\n",
      "[20]\ttrain's auc: 0.957653\tvalid's auc: 0.741151\n",
      "[30]\ttrain's auc: 0.957485\tvalid's auc: 0.74016\n",
      "[40]\ttrain's auc: 0.957554\tvalid's auc: 0.753127\n",
      "[50]\ttrain's auc: 0.957298\tvalid's auc: 0.752856\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[18]\ttrain's auc: 0.957767\tvalid's auc: 0.741149\n",
      "Fold: 3\n",
      "val_cid [40 41 42 43 44]\n",
      "(128426, 16) (894765, 16)\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.959043\tvalid's auc: 0.724628\n",
      "[20]\ttrain's auc: 0.958536\tvalid's auc: 0.725294\n",
      "[30]\ttrain's auc: 0.958994\tvalid's auc: 0.724168\n",
      "[40]\ttrain's auc: 0.958844\tvalid's auc: 0.723607\n",
      "[50]\ttrain's auc: 0.959404\tvalid's auc: 0.724542\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[13]\ttrain's auc: 0.95958\tvalid's auc: 0.725282\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957196\tvalid's auc: 0.723267\n",
      "[20]\ttrain's auc: 0.957568\tvalid's auc: 0.726999\n",
      "[30]\ttrain's auc: 0.957381\tvalid's auc: 0.727038\n",
      "[40]\ttrain's auc: 0.958127\tvalid's auc: 0.728767\n",
      "[50]\ttrain's auc: 0.958506\tvalid's auc: 0.728943\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[51]\ttrain's auc: 0.958598\tvalid's auc: 0.728967\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957409\tvalid's auc: 0.724771\n",
      "[20]\ttrain's auc: 0.957839\tvalid's auc: 0.726644\n",
      "[30]\ttrain's auc: 0.957793\tvalid's auc: 0.726089\n",
      "[40]\ttrain's auc: 0.958122\tvalid's auc: 0.724817\n",
      "[50]\ttrain's auc: 0.958601\tvalid's auc: 0.724415\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.959014\tvalid's auc: 0.724543\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.955877\tvalid's auc: 0.722508\n",
      "[20]\ttrain's auc: 0.957748\tvalid's auc: 0.72571\n",
      "[30]\ttrain's auc: 0.958169\tvalid's auc: 0.725367\n",
      "[40]\ttrain's auc: 0.958399\tvalid's auc: 0.725168\n",
      "[50]\ttrain's auc: 0.95847\tvalid's auc: 0.725506\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.958574\tvalid's auc: 0.726132\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957648\tvalid's auc: 0.719033\n",
      "[20]\ttrain's auc: 0.958564\tvalid's auc: 0.720191\n",
      "[30]\ttrain's auc: 0.958778\tvalid's auc: 0.722423\n",
      "[40]\ttrain's auc: 0.958336\tvalid's auc: 0.72308\n",
      "[50]\ttrain's auc: 0.958835\tvalid's auc: 0.723032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[52]\ttrain's auc: 0.958914\tvalid's auc: 0.723603\n",
      "Fold: 4\n",
      "val_cid [45 46 47 48 49]\n",
      "(162197, 16) (860994, 16)\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.956501\tvalid's auc: 0.699103\n",
      "[20]\ttrain's auc: 0.956945\tvalid's auc: 0.699137\n",
      "[30]\ttrain's auc: 0.957919\tvalid's auc: 0.699498\n",
      "[40]\ttrain's auc: 0.958046\tvalid's auc: 0.703426\n",
      "[50]\ttrain's auc: 0.959006\tvalid's auc: 0.711483\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.959152\tvalid's auc: 0.712056\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.958598\tvalid's auc: 0.71064\n",
      "[20]\ttrain's auc: 0.959706\tvalid's auc: 0.715877\n",
      "[30]\ttrain's auc: 0.959755\tvalid's auc: 0.714485\n",
      "[40]\ttrain's auc: 0.95969\tvalid's auc: 0.711536\n",
      "[50]\ttrain's auc: 0.96003\tvalid's auc: 0.710615\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[48]\ttrain's auc: 0.960204\tvalid's auc: 0.710831\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.956184\tvalid's auc: 0.714624\n",
      "[20]\ttrain's auc: 0.95912\tvalid's auc: 0.711213\n",
      "[30]\ttrain's auc: 0.959379\tvalid's auc: 0.710565\n",
      "[40]\ttrain's auc: 0.959882\tvalid's auc: 0.710499\n",
      "[50]\ttrain's auc: 0.959987\tvalid's auc: 0.711409\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[49]\ttrain's auc: 0.960066\tvalid's auc: 0.71145\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957558\tvalid's auc: 0.694027\n",
      "[20]\ttrain's auc: 0.959607\tvalid's auc: 0.711264\n",
      "[30]\ttrain's auc: 0.959002\tvalid's auc: 0.710682\n",
      "[40]\ttrain's auc: 0.95812\tvalid's auc: 0.702361\n",
      "[50]\ttrain's auc: 0.9582\tvalid's auc: 0.702199\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\ttrain's auc: 0.959607\tvalid's auc: 0.711264\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.956362\tvalid's auc: 0.715147\n",
      "[20]\ttrain's auc: 0.956859\tvalid's auc: 0.714264\n",
      "[30]\ttrain's auc: 0.958672\tvalid's auc: 0.71371\n",
      "[40]\ttrain's auc: 0.95855\tvalid's auc: 0.704427\n",
      "[50]\ttrain's auc: 0.959516\tvalid's auc: 0.704593\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[52]\ttrain's auc: 0.959685\tvalid's auc: 0.704602\n",
      "Fold: 5\n",
      "val_cid [50 51 52 53 54]\n",
      "(305126, 16) (718065, 16)\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.959101\tvalid's auc: 0.648002\n",
      "[20]\ttrain's auc: 0.960381\tvalid's auc: 0.650036\n",
      "[30]\ttrain's auc: 0.960476\tvalid's auc: 0.654387\n",
      "[40]\ttrain's auc: 0.96103\tvalid's auc: 0.654446\n",
      "[50]\ttrain's auc: 0.961455\tvalid's auc: 0.654559\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[53]\ttrain's auc: 0.9617\tvalid's auc: 0.654462\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.959621\tvalid's auc: 0.654011\n",
      "[20]\ttrain's auc: 0.960735\tvalid's auc: 0.653463\n",
      "[30]\ttrain's auc: 0.960836\tvalid's auc: 0.6549\n",
      "[40]\ttrain's auc: 0.961172\tvalid's auc: 0.654521\n",
      "[50]\ttrain's auc: 0.961256\tvalid's auc: 0.653726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[17]\ttrain's auc: 0.961457\tvalid's auc: 0.654111\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.95697\tvalid's auc: 0.65449\n",
      "[20]\ttrain's auc: 0.960161\tvalid's auc: 0.655808\n",
      "[30]\ttrain's auc: 0.960082\tvalid's auc: 0.655498\n",
      "[40]\ttrain's auc: 0.960535\tvalid's auc: 0.655341\n",
      "[50]\ttrain's auc: 0.960987\tvalid's auc: 0.654711\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.961063\tvalid's auc: 0.654381\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.958435\tvalid's auc: 0.650125\n",
      "[20]\ttrain's auc: 0.960372\tvalid's auc: 0.650232\n",
      "[30]\ttrain's auc: 0.961111\tvalid's auc: 0.652803\n",
      "[40]\ttrain's auc: 0.960978\tvalid's auc: 0.654544\n",
      "[50]\ttrain's auc: 0.961009\tvalid's auc: 0.65462\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[45]\ttrain's auc: 0.961195\tvalid's auc: 0.655012\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.960162\tvalid's auc: 0.654207\n",
      "[20]\ttrain's auc: 0.961086\tvalid's auc: 0.653852\n",
      "[30]\ttrain's auc: 0.961252\tvalid's auc: 0.654194\n",
      "[40]\ttrain's auc: 0.961249\tvalid's auc: 0.654152\n",
      "[50]\ttrain's auc: 0.961266\tvalid's auc: 0.654177\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.961397\tvalid's auc: 0.654149\n"
     ]
    }
   ],
   "source": [
    "nfold =5\n",
    "kf = KFold(n_splits=nfold,random_state=123,shuffle=False)\n",
    "unq_campaign_id = np.sort(train.campaign_id.unique())\n",
    "\n",
    "test_subm = test[['id']]\n",
    "test_subm['is_click'] = 0\n",
    "train_score = train[['is_click']]\n",
    "train_score['pred'] = 0\n",
    "nbag = 5\n",
    "cf =0\n",
    "for train_index, test_index in kf.split(unq_campaign_id):\n",
    "    cf+=1\n",
    "    print('Fold:',cf)\n",
    "    \n",
    "    test1 = test.copy()\n",
    "    tr_cid = unq_campaign_id[train_index]\n",
    "    val_cid = unq_campaign_id[test_index]\n",
    "    print('val_cid',val_cid)\n",
    "\n",
    "    val = train[train.campaign_id.isin(val_cid)]\n",
    "    train1 = train[train.campaign_id.isin(tr_cid)]\n",
    "    print(val.shape,train1.shape)\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['user_id'],val['user_id'],\n",
    "                             test1['user_id'],train1.is_click,noise_level=.9,smoothing=5)\n",
    "    train1.loc[:,'mean_is_click'] = a1\n",
    "    val.loc[:,'mean_is_click'] = a2\n",
    "    test1.loc[:,'mean_is_click'] = a3\n",
    "\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['user_id'],val['user_id'],\n",
    "                             test1['user_id'],train1.is_open,noise_level=.9,smoothing=1.)\n",
    "    train1.loc[:,'mean_is_open'] = a1\n",
    "    val.loc[:,'mean_is_open'] = a2\n",
    "    test1.loc[:,'mean_is_open'] = a3\n",
    "\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['communication_type'],val['communication_type'],\n",
    "                             test1['communication_type'],train1.is_open,noise_level=0)\n",
    "    train1.loc[:,'mean_ct'] = a1\n",
    "    val.loc[:,'mean_ct'] = a2\n",
    "    test1.loc[:,'mean_ct'] = a3\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['communication_type'],val['communication_type'],\n",
    "                             test1['communication_type'],train1.is_click,noise_level=0)\n",
    "    train1.loc[:,'mean_clk_ct'] = a1\n",
    "    val.loc[:,'mean_clk_ct'] = a2\n",
    "    test1.loc[:,'mean_clk_ct'] = a3\n",
    "\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['clust_id'],val['clust_id'],\n",
    "                             test1['clust_id'],train1.is_click,noise_level=0)\n",
    "    train1.loc[:,'mean_clk_clust_id'] = a1\n",
    "    val.loc[:,'mean_clk_clust_id'] = a2\n",
    "    test1.loc[:,'mean_clk_clust_id'] = a3\n",
    "\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "    val.drop(['id','campaign_id','is_open','send_date',\n",
    "              'user_id','no_of_images','no_of_sections','no_of_internal_links'],axis=1,inplace=True)\n",
    "    train1.drop(['id','campaign_id','is_open','send_date',\n",
    "                 'user_id','no_of_images','no_of_sections','no_of_internal_links'],axis=1,inplace=True)\n",
    "    test1.drop(['id','campaign_id','is_open','send_date',\n",
    "               'user_id','no_of_images','no_of_sections','no_of_internal_links'],axis=1,inplace=True)\n",
    "    gc.collect()\n",
    "    train_y = train1.is_click.values\n",
    "    val_y = val.is_click.values\n",
    "    val.drop(['is_click'],axis=1,inplace=True)\n",
    "    train1.drop(['is_click'],axis=1,inplace=True)\n",
    "    test1.drop(['is_click'],axis=1,inplace=True)\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train1, label=train_y,categorical_feature=['communication_type','send_dayofweek','clust_id'],\n",
    "                      free_raw_data=False)\n",
    "    lgvalid = lgb.Dataset(val, label=val_y,categorical_feature=['communication_type','send_dayofweek','clust_id'],\n",
    "                     free_raw_data=False)\n",
    "    gc.collect()\n",
    "    \n",
    "    evals_results = {}\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    test_subm['is_click'+str(cf)]=0\n",
    "    \n",
    "    for bg in range(nbag):\n",
    "        lgb_params['feature_fraction_seed'] = 100*cf + bg\n",
    "        bst1 = lgb.train(lgb_params, \n",
    "                     lgtrain, \n",
    "                     valid_sets=[lgtrain, lgvalid], \n",
    "                     valid_names=['train','valid'], \n",
    "                     evals_result=evals_results, \n",
    "                     num_boost_round=55,\n",
    "                     early_stopping_rounds=1000,\n",
    "                     verbose_eval=10)\n",
    "        train_score.loc[val.index,'pred'] += bst1.predict(val[train1.columns],num_iteration=51)\n",
    "        test_subm['is_click'+str(cf)] += bst1.predict(test1[train1.columns],num_iteration=51)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_score['pred']/=nbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6198733764612789"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_score.is_click,train_score.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "test_subm.loc[:,'is_click'] = (test_subm['is_click1'].rank()/test_subm.shape[0] +\\\n",
    "test_subm['is_click2'].rank()/test_subm.shape[0] + test_subm['is_click3'].rank()/test_subm.shape[0])/nfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subm[['id','is_click']].to_csv('./lgb_5fold-5_bag_nt55_rank_average.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
