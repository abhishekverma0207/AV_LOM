{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campaign  = pd.read_csv('input/campaign_data.csv')\n",
    "campaign1 = campaign.drop(['subject','email_url','email_body'],axis=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "def target_encode(trn_series=None,val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    #assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_val_series.index = val_series.index\n",
    "    \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), ft_val_series,ft_tst_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_clust = pd.read_csv('./input/user_cluster1.csv')\n",
    "all_data = all_data.merge(user_clust,on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['send_date'] = all_data.send_date.apply(lambda x: pd.datetime.strptime(x,'%d-%m-%Y %H:%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['send_dayofweek'] = all_data.send_date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'id', 'is_click', 'is_open', 'send_date', 'user_id',\n",
       "       'clust_id', 'send_dayofweek'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count features\n",
    "all_data['cnt_sd'] = all_data.groupby('send_date')['user_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.merge(campaign1,on='campaign_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'id', 'is_click', 'is_open', 'send_date', 'user_id',\n",
       "       'clust_id', 'send_dayofweek', 'cnt_sd', 'communication_type',\n",
       "       'total_links', 'no_of_internal_links', 'no_of_images',\n",
       "       'no_of_sections'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "all_data.loc[:,'communication_type'] = le1.fit_transform(all_data.communication_type)   \n",
    "all_data['usr_cnt'] = all_data.groupby('user_id')['user_id'].transform('count')\n",
    "all_data['cm_cnt'] = np.log(all_data.groupby('communication_type')['communication_type'].transform('count'))\n",
    "#all_data['camp_cnt'] = all_data.groupby('campaign_id')['campaign_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_data[len(train):]\n",
    "train = all_data[:len(train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del all_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['num_leaves'] = 31\n",
    "lgb_params['max_depth'] = 5\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['min_data_in_leaf'] = 50\n",
    "lgb_params['subsample'] = 0.6\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['feature_fraction'] = 0.77,\n",
    "lgb_params['bagging_fraction'] = 0.77,\n",
    "lgb_params['objective'] = 'binary'\n",
    "lgb_params['metric'] = {'auc'}\n",
    "lgb_params['verbose'] = 1\n",
    "lgb_params['scale_pos_weight'] = 1.\n",
    "lgb_params['boosting_type'] = 'gbdt'\n",
    "lgb_params['min_split_gain'] = 0.0001\n",
    "#lgb_params['bagging_fraction'] = 0.7\n",
    "lgb_params['bagging_freq'] = 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "val_cid [29 30 31 32 33 34]\n",
      "(331628, 16) (691563, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.962805\tvalid's auc: 0.674618\n",
      "[20]\ttrain's auc: 0.963193\tvalid's auc: 0.68505\n",
      "[30]\ttrain's auc: 0.963489\tvalid's auc: 0.68306\n",
      "[40]\ttrain's auc: 0.96343\tvalid's auc: 0.685816\n",
      "[50]\ttrain's auc: 0.963585\tvalid's auc: 0.68531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[15]\ttrain's auc: 0.96401\tvalid's auc: 0.687131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.958735\tvalid's auc: 0.67823\n",
      "[20]\ttrain's auc: 0.956856\tvalid's auc: 0.678421\n",
      "[30]\ttrain's auc: 0.958005\tvalid's auc: 0.674503\n",
      "[40]\ttrain's auc: 0.959854\tvalid's auc: 0.681749\n",
      "[50]\ttrain's auc: 0.960658\tvalid's auc: 0.681605\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[46]\ttrain's auc: 0.961148\tvalid's auc: 0.681517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.962397\tvalid's auc: 0.681139\n",
      "[20]\ttrain's auc: 0.963666\tvalid's auc: 0.681113\n",
      "[30]\ttrain's auc: 0.96332\tvalid's auc: 0.689459\n",
      "[40]\ttrain's auc: 0.963309\tvalid's auc: 0.689208\n",
      "[50]\ttrain's auc: 0.964175\tvalid's auc: 0.689181\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.964218\tvalid's auc: 0.689003\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.961895\tvalid's auc: 0.679073\n",
      "[20]\ttrain's auc: 0.962721\tvalid's auc: 0.680552\n",
      "[30]\ttrain's auc: 0.963843\tvalid's auc: 0.684549\n",
      "[40]\ttrain's auc: 0.963979\tvalid's auc: 0.684159\n",
      "[50]\ttrain's auc: 0.964223\tvalid's auc: 0.685265\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[48]\ttrain's auc: 0.964333\tvalid's auc: 0.684591\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.961093\tvalid's auc: 0.688025\n",
      "[20]\ttrain's auc: 0.960536\tvalid's auc: 0.688727\n",
      "[30]\ttrain's auc: 0.961975\tvalid's auc: 0.689075\n",
      "[40]\ttrain's auc: 0.963041\tvalid's auc: 0.688976\n",
      "[50]\ttrain's auc: 0.963335\tvalid's auc: 0.688792\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[44]\ttrain's auc: 0.963517\tvalid's auc: 0.688553\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.962762\tvalid's auc: 0.676238\n",
      "[20]\ttrain's auc: 0.964489\tvalid's auc: 0.683906\n",
      "[30]\ttrain's auc: 0.964298\tvalid's auc: 0.682718\n",
      "[40]\ttrain's auc: 0.964362\tvalid's auc: 0.685107\n",
      "[50]\ttrain's auc: 0.964241\tvalid's auc: 0.686554\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[23]\ttrain's auc: 0.964557\tvalid's auc: 0.683846\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.9632\tvalid's auc: 0.689975\n",
      "[20]\ttrain's auc: 0.963446\tvalid's auc: 0.689402\n",
      "[30]\ttrain's auc: 0.963618\tvalid's auc: 0.689002\n",
      "[40]\ttrain's auc: 0.963498\tvalid's auc: 0.690037\n",
      "[50]\ttrain's auc: 0.963441\tvalid's auc: 0.69049\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[14]\ttrain's auc: 0.963987\tvalid's auc: 0.689057\n",
      "Fold: 2\n",
      "val_cid [35 36 37 38 39]\n",
      "(95814, 16) (927377, 16)\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957837\tvalid's auc: 0.741696\n",
      "[20]\ttrain's auc: 0.957346\tvalid's auc: 0.742624\n",
      "[30]\ttrain's auc: 0.957826\tvalid's auc: 0.754775\n",
      "[40]\ttrain's auc: 0.957801\tvalid's auc: 0.756394\n",
      "[50]\ttrain's auc: 0.957534\tvalid's auc: 0.754707\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[15]\ttrain's auc: 0.957959\tvalid's auc: 0.742427\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.950259\tvalid's auc: 0.75358\n",
      "[20]\ttrain's auc: 0.95636\tvalid's auc: 0.752324\n",
      "[30]\ttrain's auc: 0.956595\tvalid's auc: 0.752097\n",
      "[40]\ttrain's auc: 0.95704\tvalid's auc: 0.756604\n",
      "[50]\ttrain's auc: 0.95715\tvalid's auc: 0.761895\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[43]\ttrain's auc: 0.957289\tvalid's auc: 0.756431\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.953097\tvalid's auc: 0.742677\n",
      "[20]\ttrain's auc: 0.95651\tvalid's auc: 0.753205\n",
      "[30]\ttrain's auc: 0.956647\tvalid's auc: 0.754191\n",
      "[40]\ttrain's auc: 0.956437\tvalid's auc: 0.760314\n",
      "[50]\ttrain's auc: 0.956908\tvalid's auc: 0.76152\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[54]\ttrain's auc: 0.957242\tvalid's auc: 0.761702\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.956544\tvalid's auc: 0.730328\n",
      "[20]\ttrain's auc: 0.95732\tvalid's auc: 0.758383\n",
      "[30]\ttrain's auc: 0.957757\tvalid's auc: 0.760226\n",
      "[40]\ttrain's auc: 0.957904\tvalid's auc: 0.759536\n",
      "[50]\ttrain's auc: 0.957963\tvalid's auc: 0.759187\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.958139\tvalid's auc: 0.759085\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957626\tvalid's auc: 0.741357\n",
      "[20]\ttrain's auc: 0.957792\tvalid's auc: 0.741287\n",
      "[30]\ttrain's auc: 0.957804\tvalid's auc: 0.741008\n",
      "[40]\ttrain's auc: 0.957864\tvalid's auc: 0.752884\n",
      "[50]\ttrain's auc: 0.957589\tvalid's auc: 0.752362\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[36]\ttrain's auc: 0.957933\tvalid's auc: 0.753061\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.956236\tvalid's auc: 0.7421\n",
      "[20]\ttrain's auc: 0.956859\tvalid's auc: 0.740484\n",
      "[30]\ttrain's auc: 0.95721\tvalid's auc: 0.751406\n",
      "[40]\ttrain's auc: 0.957543\tvalid's auc: 0.750706\n",
      "[50]\ttrain's auc: 0.95746\tvalid's auc: 0.751501\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[37]\ttrain's auc: 0.95765\tvalid's auc: 0.750734\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.953589\tvalid's auc: 0.734123\n",
      "[20]\ttrain's auc: 0.955791\tvalid's auc: 0.753553\n",
      "[30]\ttrain's auc: 0.95559\tvalid's auc: 0.753862\n",
      "[40]\ttrain's auc: 0.956774\tvalid's auc: 0.75324\n",
      "[50]\ttrain's auc: 0.957286\tvalid's auc: 0.753196\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.957404\tvalid's auc: 0.754271\n",
      "Fold: 3\n",
      "val_cid [40 41 42 43 44]\n",
      "(128426, 16) (894765, 16)\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.958708\tvalid's auc: 0.723786\n",
      "[20]\ttrain's auc: 0.958558\tvalid's auc: 0.724551\n",
      "[30]\ttrain's auc: 0.958827\tvalid's auc: 0.725412\n",
      "[40]\ttrain's auc: 0.95893\tvalid's auc: 0.72525\n",
      "[50]\ttrain's auc: 0.959376\tvalid's auc: 0.726072\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.959483\tvalid's auc: 0.727388\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957846\tvalid's auc: 0.7234\n",
      "[20]\ttrain's auc: 0.958193\tvalid's auc: 0.724437\n",
      "[30]\ttrain's auc: 0.958335\tvalid's auc: 0.723064\n",
      "[40]\ttrain's auc: 0.958508\tvalid's auc: 0.722841\n",
      "[50]\ttrain's auc: 0.958715\tvalid's auc: 0.72309\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[51]\ttrain's auc: 0.958772\tvalid's auc: 0.723096\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.956849\tvalid's auc: 0.706196\n",
      "[20]\ttrain's auc: 0.957985\tvalid's auc: 0.719805\n",
      "[30]\ttrain's auc: 0.958655\tvalid's auc: 0.723716\n",
      "[40]\ttrain's auc: 0.958706\tvalid's auc: 0.724361\n",
      "[50]\ttrain's auc: 0.959017\tvalid's auc: 0.724936\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.959265\tvalid's auc: 0.725058\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.95803\tvalid's auc: 0.719612\n",
      "[20]\ttrain's auc: 0.958647\tvalid's auc: 0.719636\n",
      "[30]\ttrain's auc: 0.958629\tvalid's auc: 0.722037\n",
      "[40]\ttrain's auc: 0.9587\tvalid's auc: 0.722886\n",
      "[50]\ttrain's auc: 0.958843\tvalid's auc: 0.72504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.959099\tvalid's auc: 0.72525\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.958615\tvalid's auc: 0.724866\n",
      "[20]\ttrain's auc: 0.958813\tvalid's auc: 0.724175\n",
      "[30]\ttrain's auc: 0.959362\tvalid's auc: 0.724861\n",
      "[40]\ttrain's auc: 0.959077\tvalid's auc: 0.726781\n",
      "[50]\ttrain's auc: 0.959259\tvalid's auc: 0.727006\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[29]\ttrain's auc: 0.959467\tvalid's auc: 0.724872\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957962\tvalid's auc: 0.72543\n",
      "[20]\ttrain's auc: 0.957966\tvalid's auc: 0.727607\n",
      "[30]\ttrain's auc: 0.957982\tvalid's auc: 0.727242\n",
      "[40]\ttrain's auc: 0.958512\tvalid's auc: 0.727139\n",
      "[50]\ttrain's auc: 0.958726\tvalid's auc: 0.726226\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[47]\ttrain's auc: 0.958853\tvalid's auc: 0.726373\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.954205\tvalid's auc: 0.726371\n",
      "[20]\ttrain's auc: 0.957853\tvalid's auc: 0.725541\n",
      "[30]\ttrain's auc: 0.958272\tvalid's auc: 0.725361\n",
      "[40]\ttrain's auc: 0.958578\tvalid's auc: 0.724105\n",
      "[50]\ttrain's auc: 0.958804\tvalid's auc: 0.724849\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[53]\ttrain's auc: 0.958923\tvalid's auc: 0.72486\n",
      "Fold: 4\n",
      "val_cid [45 46 47 48 49]\n",
      "(162197, 16) (860994, 16)\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.958729\tvalid's auc: 0.7051\n",
      "[20]\ttrain's auc: 0.958273\tvalid's auc: 0.703559\n",
      "[30]\ttrain's auc: 0.959035\tvalid's auc: 0.699326\n",
      "[40]\ttrain's auc: 0.959556\tvalid's auc: 0.699609\n",
      "[50]\ttrain's auc: 0.959787\tvalid's auc: 0.702375\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.959918\tvalid's auc: 0.711167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957479\tvalid's auc: 0.689646\n",
      "[20]\ttrain's auc: 0.959953\tvalid's auc: 0.71164\n",
      "[30]\ttrain's auc: 0.960348\tvalid's auc: 0.71069\n",
      "[40]\ttrain's auc: 0.960473\tvalid's auc: 0.710728\n",
      "[50]\ttrain's auc: 0.960472\tvalid's auc: 0.71061\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.960592\tvalid's auc: 0.710661\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.958059\tvalid's auc: 0.713996\n",
      "[20]\ttrain's auc: 0.959824\tvalid's auc: 0.710924\n",
      "[30]\ttrain's auc: 0.959983\tvalid's auc: 0.710757\n",
      "[40]\ttrain's auc: 0.960269\tvalid's auc: 0.710889\n",
      "[50]\ttrain's auc: 0.960259\tvalid's auc: 0.711001\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[49]\ttrain's auc: 0.960388\tvalid's auc: 0.711046\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957215\tvalid's auc: 0.693773\n",
      "[20]\ttrain's auc: 0.959706\tvalid's auc: 0.699633\n",
      "[30]\ttrain's auc: 0.959715\tvalid's auc: 0.699774\n",
      "[40]\ttrain's auc: 0.959136\tvalid's auc: 0.699273\n",
      "[50]\ttrain's auc: 0.958877\tvalid's auc: 0.703118\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[25]\ttrain's auc: 0.959848\tvalid's auc: 0.699666\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.958145\tvalid's auc: 0.700051\n",
      "[20]\ttrain's auc: 0.95866\tvalid's auc: 0.705686\n",
      "[30]\ttrain's auc: 0.959574\tvalid's auc: 0.701186\n",
      "[40]\ttrain's auc: 0.959324\tvalid's auc: 0.6971\n",
      "[50]\ttrain's auc: 0.9599\tvalid's auc: 0.699553\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[54]\ttrain's auc: 0.960018\tvalid's auc: 0.699542\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.95885\tvalid's auc: 0.701604\n",
      "[20]\ttrain's auc: 0.959959\tvalid's auc: 0.695782\n",
      "[30]\ttrain's auc: 0.960358\tvalid's auc: 0.695879\n",
      "[40]\ttrain's auc: 0.959479\tvalid's auc: 0.70602\n",
      "[50]\ttrain's auc: 0.96003\tvalid's auc: 0.706031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[30]\ttrain's auc: 0.960358\tvalid's auc: 0.695879\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.959979\tvalid's auc: 0.696006\n",
      "[20]\ttrain's auc: 0.959654\tvalid's auc: 0.699502\n",
      "[30]\ttrain's auc: 0.959393\tvalid's auc: 0.70354\n",
      "[40]\ttrain's auc: 0.959506\tvalid's auc: 0.70314\n",
      "[50]\ttrain's auc: 0.959354\tvalid's auc: 0.702418\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[16]\ttrain's auc: 0.959992\tvalid's auc: 0.692888\n",
      "Fold: 5\n",
      "val_cid [50 51 52 53 54]\n",
      "(305126, 16) (718065, 16)\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.960725\tvalid's auc: 0.64776\n",
      "[20]\ttrain's auc: 0.961083\tvalid's auc: 0.651149\n",
      "[30]\ttrain's auc: 0.961015\tvalid's auc: 0.650652\n",
      "[40]\ttrain's auc: 0.961514\tvalid's auc: 0.6505\n",
      "[50]\ttrain's auc: 0.961646\tvalid's auc: 0.650413\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[45]\ttrain's auc: 0.96184\tvalid's auc: 0.65063\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.960936\tvalid's auc: 0.646585\n",
      "[20]\ttrain's auc: 0.960971\tvalid's auc: 0.646821\n",
      "[30]\ttrain's auc: 0.960755\tvalid's auc: 0.646951\n",
      "[40]\ttrain's auc: 0.96144\tvalid's auc: 0.646945\n",
      "[50]\ttrain's auc: 0.961434\tvalid's auc: 0.646256\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[38]\ttrain's auc: 0.961607\tvalid's auc: 0.647204\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.957662\tvalid's auc: 0.656201\n",
      "[20]\ttrain's auc: 0.961079\tvalid's auc: 0.654869\n",
      "[30]\ttrain's auc: 0.960852\tvalid's auc: 0.654704\n",
      "[40]\ttrain's auc: 0.96108\tvalid's auc: 0.654679\n",
      "[50]\ttrain's auc: 0.961673\tvalid's auc: 0.654479\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[52]\ttrain's auc: 0.96176\tvalid's auc: 0.654465\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.958021\tvalid's auc: 0.654735\n",
      "[20]\ttrain's auc: 0.961072\tvalid's auc: 0.655313\n",
      "[30]\ttrain's auc: 0.961688\tvalid's auc: 0.653888\n",
      "[40]\ttrain's auc: 0.961461\tvalid's auc: 0.653463\n",
      "[50]\ttrain's auc: 0.96151\tvalid's auc: 0.654212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[30]\ttrain's auc: 0.961688\tvalid's auc: 0.653888\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.959929\tvalid's auc: 0.655169\n",
      "[20]\ttrain's auc: 0.960528\tvalid's auc: 0.654105\n",
      "[30]\ttrain's auc: 0.961006\tvalid's auc: 0.654103\n",
      "[40]\ttrain's auc: 0.961188\tvalid's auc: 0.654267\n",
      "[50]\ttrain's auc: 0.961426\tvalid's auc: 0.654272\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[55]\ttrain's auc: 0.961564\tvalid's auc: 0.654073\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.960208\tvalid's auc: 0.647288\n",
      "[20]\ttrain's auc: 0.960197\tvalid's auc: 0.654469\n",
      "[30]\ttrain's auc: 0.96085\tvalid's auc: 0.653618\n",
      "[40]\ttrain's auc: 0.961249\tvalid's auc: 0.654156\n",
      "[50]\ttrain's auc: 0.961499\tvalid's auc: 0.654275\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[53]\ttrain's auc: 0.961685\tvalid's auc: 0.654173\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[10]\ttrain's auc: 0.95994\tvalid's auc: 0.653752\n",
      "[20]\ttrain's auc: 0.960754\tvalid's auc: 0.654669\n",
      "[30]\ttrain's auc: 0.961027\tvalid's auc: 0.654471\n",
      "[40]\ttrain's auc: 0.961407\tvalid's auc: 0.655162\n",
      "[50]\ttrain's auc: 0.961733\tvalid's auc: 0.654737\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[51]\ttrain's auc: 0.961785\tvalid's auc: 0.65474\n"
     ]
    }
   ],
   "source": [
    "nfold =5\n",
    "kf = KFold(n_splits=nfold,random_state=123,shuffle=False)\n",
    "unq_campaign_id = np.sort(train.campaign_id.unique())\n",
    "\n",
    "test_subm = test[['id']]\n",
    "test_subm['is_click'] = 0\n",
    "train_score = train[['is_click']]\n",
    "train_score['pred'] = 0\n",
    "nbag = 7\n",
    "cf =0\n",
    "for train_index, test_index in kf.split(unq_campaign_id):\n",
    "    cf+=1\n",
    "    print('Fold:',cf)\n",
    "    \n",
    "    test1 = test.copy()\n",
    "    tr_cid = unq_campaign_id[train_index]\n",
    "    val_cid = unq_campaign_id[test_index]\n",
    "    print('val_cid',val_cid)\n",
    "\n",
    "    val = train[train.campaign_id.isin(val_cid)]\n",
    "    train1 = train[train.campaign_id.isin(tr_cid)]\n",
    "    print(val.shape,train1.shape)\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['user_id'],val['user_id'],\n",
    "                             test1['user_id'],train1.is_click,noise_level=.9,smoothing=5)\n",
    "    train1.loc[:,'mean_is_click'] = a1\n",
    "    val.loc[:,'mean_is_click'] = a2\n",
    "    test1.loc[:,'mean_is_click'] = a3\n",
    "\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['user_id'],val['user_id'],\n",
    "                             test1['user_id'],train1.is_open,noise_level=.9,smoothing=1.2)\n",
    "    train1.loc[:,'mean_is_open'] = a1\n",
    "    val.loc[:,'mean_is_open'] = a2\n",
    "    test1.loc[:,'mean_is_open'] = a3\n",
    "\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['communication_type'],val['communication_type'],\n",
    "                             test1['communication_type'],train1.is_open,noise_level=0)\n",
    "    train1.loc[:,'mean_ct'] = a1\n",
    "    val.loc[:,'mean_ct'] = a2\n",
    "    test1.loc[:,'mean_ct'] = a3\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['communication_type'],val['communication_type'],\n",
    "                             test1['communication_type'],train1.is_click,noise_level=0)\n",
    "    train1.loc[:,'mean_clk_ct'] = a1\n",
    "    val.loc[:,'mean_clk_ct'] = a2\n",
    "    test1.loc[:,'mean_clk_ct'] = a3\n",
    "\n",
    "\n",
    "    a1,a2,a3 = target_encode(train1['clust_id'],val['clust_id'],\n",
    "                             test1['clust_id'],train1.is_click,noise_level=0)\n",
    "    train1.loc[:,'mean_clk_clust_id'] = a1\n",
    "    val.loc[:,'mean_clk_clust_id'] = a2\n",
    "    test1.loc[:,'mean_clk_clust_id'] = a3\n",
    "\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "    val.drop(['id','campaign_id','is_open','send_date',\n",
    "              'user_id','no_of_images','no_of_sections','no_of_internal_links'],axis=1,inplace=True)\n",
    "    train1.drop(['id','campaign_id','is_open','send_date',\n",
    "                 'user_id','no_of_images','no_of_sections','no_of_internal_links'],axis=1,inplace=True)\n",
    "    test1.drop(['id','campaign_id','is_open','send_date',\n",
    "               'user_id','no_of_images','no_of_sections','no_of_internal_links'],axis=1,inplace=True)\n",
    "    gc.collect()\n",
    "    train_y = train1.is_click.values\n",
    "    val_y = val.is_click.values\n",
    "    val.drop(['is_click'],axis=1,inplace=True)\n",
    "    train1.drop(['is_click'],axis=1,inplace=True)\n",
    "    test1.drop(['is_click'],axis=1,inplace=True)\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train1, label=train_y,categorical_feature=['communication_type','send_dayofweek','clust_id'],\n",
    "                      free_raw_data=False)\n",
    "    lgvalid = lgb.Dataset(val, label=val_y,categorical_feature=['communication_type','send_dayofweek','clust_id'],\n",
    "                     free_raw_data=False)\n",
    "    gc.collect()\n",
    "    \n",
    "    evals_results = {}\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    test_subm['is_click'+str(cf)]=0\n",
    "    \n",
    "    for bg in range(nbag):\n",
    "        lgb_params['feature_fraction_seed'] = 100*cf + bg\n",
    "        bst1 = lgb.train(lgb_params, \n",
    "                     lgtrain, \n",
    "                     valid_sets=[lgtrain, lgvalid], \n",
    "                     valid_names=['train','valid'], \n",
    "                     evals_result=evals_results, \n",
    "                     num_boost_round=55,\n",
    "                     early_stopping_rounds=1000,\n",
    "                     verbose_eval=10)\n",
    "        train_score.loc[val.index,'pred'] += bst1.predict(val[train1.columns],num_iteration=45)\n",
    "        test_subm['is_click'+str(cf)] += bst1.predict(test1[train1.columns],num_iteration=45)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esinadi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_score['pred']/=nbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6315854523976097"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_score.is_click,train_score.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subm.loc[:,'is_click'] = (test_subm['is_click1'].rank()/test_subm.shape[0] +\\\n",
    "test_subm['is_click2'].rank()/test_subm.shape[0] + test_subm['is_click3'].rank()/test_subm.shape[0]+\\\n",
    "test_subm['is_click4'].rank()/test_subm.shape[0] + test_subm['is_click5'].rank()/test_subm.shape[0])/nfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subm[['id','is_click']].to_csv('./lgb_5fold-5_bag_nt45_rank_average.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing prediction from last fold\n",
    "test_subm.loc[:,'is_click'] = (test_subm['is_click2'].rank()/test_subm.shape[0] + test_subm['is_click3'].rank()/test_subm.shape[0]+\\\n",
    "test_subm['is_click4'].rank()/test_subm.shape[0])/(nfold-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subm[['id','is_click']].to_csv('./lgb_5fold-5_bag_nt45_rank_average_4f.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
